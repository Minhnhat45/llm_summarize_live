import json
import requests
import sys

# ==== FIXED PARAMETERS ====
MODEL = "qwen3-8b-5k-quant-8-2:latest"
URL = "http://157.10.188.151:11434/v1/chat/completions"
TASK = "title"              # "title" or "lead"
STYLE = "ƒë·ªùi s·ªëng"

LEAD = (
    "Kh√°c c√°c chaebol H√†n Qu·ªëc chu·ªông h√†ng hi·ªáu hay 'ph√∫ nh·ªã ƒë·∫°i' Trung Qu·ªëc n·ªïi ti·∫øng "
    "v·ªõi si√™u xe, gi·ªõi t·ª∑ ph√∫ Nh·∫≠t th∆∞·ªùng ch·ªçn s·ªëng k√≠n ti·∫øng."
)

CONTENT = """NƒÉm 2018, b·ªô phim Crazy Rich Asians g√¢y ch√∫ √Ω to√†n c·∫ßu khi kh·∫Øc h·ªça gi·ªõi nh√† gi√†u ch√¢u √Å. 
H√¨nh ·∫£nh ng∆∞·ªùi ch√¢u √Å t·ª´ bi·ªÉu t∆∞·ª£ng c·ªßa s·ª± chƒÉm ch·ªâ ƒë√£ chuy·ªÉn th√†nh t·∫ßng l·ªõp s·∫µn s√†ng chi ti√™u 
cho c√°c m√≥n xa x·ªâ nh∆∞ t√∫i x√°ch, trang s·ª©c b·∫£n gi·ªõi h·∫°n.
... (r√∫t g·ªçn cho ng·∫Øn, gi·ªØ n·ªôi dung g·ªëc n·∫øu c·∫ßn)
"""

def build_system_prompt(task: str, style: str) -> str:
    if task == "title":
        return (
            f"[STYLE={style}][TASK={task}]\n"
            "B·∫°n l√† t·ªïng bi√™n t·∫≠p b√°o ch√≠ d√†y d·∫°n kinh nghi·ªám.\n"
            "Nhi·ªám v·ª• c·ªßa b·∫°n l√† vi·∫øt m·ªôt ti√™u ƒë·ªÅ ng·∫Øn g·ªçn, h·∫•p d·∫´n, ƒë√∫ng phong c√°ch b√°o ch√≠ chuy√™n nghi·ªáp "
            "v√† d·ªÖ hi·ªÉu v·ªõi ƒë·ªôc gi·∫£ ƒë·∫°i ch√∫ng, d·ª±a tr√™n ph·∫ßn *lead* v√† *content* ƒë∆∞·ª£c cung c·∫•p.\n"
            "Title c·∫ßn:\n"
            "- Ch·ªâ in ra ti√™u ƒë·ªÅ, KH√îNG k√®m gi·∫£i th√≠ch.\n"
            "- Ng·∫Øn g·ªçn d∆∞·ªõi 15 t·ª´, d·ªÖ hi·ªÉu, r√µ r√†ng.\n"
            "- Kh√¥ng s·ª≠ d·ª•ng '?', '!', ';', '\"'\n"
        )
    elif task == "lead":
        return (
            f"[STYLE={style}][TASK={task}]\n"
            "B·∫°n l√† t·ªïng bi√™n t·∫≠p b√°o ch√≠ d√†y d·∫°n kinh nghi·ªám.\n"
            "Nhi·ªám v·ª• c·ªßa b·∫°n l√† vi·∫øt m·ªôt ƒëo·∫°n *lead* ng·∫Øn g·ªçn, s√∫c t√≠ch v√† h·∫•p d·∫´n d·ª±a tr√™n ph·∫ßn *content* "
            "ƒë∆∞·ª£c cung c·∫•p.\n"
            "Lead c·∫ßn:\n"
            "- T√≥m t·∫Øt √Ω ch√≠nh quan tr·ªçng nh·∫•t c·ªßa b√†i vi·∫øt.\n"
            "- G√¢y t√≤ m√≤, thu h√∫t ƒë·ªôc gi·∫£ ti·∫øp t·ª•c ƒë·ªçc.\n"
            "- Vi·∫øt theo phong c√°ch b√°o ch√≠ chuy√™n nghi·ªáp, d·ªÖ hi·ªÉu v·ªõi ƒë·ªôc gi·∫£ ƒë·∫°i ch√∫ng.\n"
            "- ƒê·ªô d√†i kho·∫£ng t·ª´ 1 ƒë·∫øn 3 c√¢u.\n"
        )
    else:
        return ("B·∫°n l√† tr·ª£ l√Ω ·∫£o h·ªó tr·ª£ vi·∫øt b√†i b√°o ch√≠ chuy√™n nghi·ªáp. H√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng.")

def build_user_prompt(task: str, lead: str, content: str) -> str:
    if task == "title":
        return (
            "H√£y vi·∫øt M·ªòT ti√™u ƒë·ªÅ duy nh·∫•t d·ª±a tr√™n LEAD v√† CONTENT sau.\n\n"
            f"LEAD:\n{lead}\n\n"
            f"CONTENT:\n{content}\n"
        )
    elif task == "lead":
        return (
            "T·∫°o LEAD v·ªõi ƒë·ªô d√†i t·ª´ 1 ƒë·∫øn 3 c√¢u cho b√†i vi·∫øt d·ª±a tr√™n CONTENT sau.\n\n"
            f"CONTENT:\n{content}\n"
        )
    else:
        return "Xin ch√†o, b·∫°n kh·ªèe kh√¥ng?"

def call_ollama():
    system_prompt = build_system_prompt(TASK, STYLE)
    user_prompt = build_user_prompt(TASK, LEAD, CONTENT)

    # === Log like the bash script ===
    print("\n=== SYSTEM PROMPT ===")
    print(system_prompt)
    print("\n=== USER PROMPT ===")
    print(user_prompt)
    print(f"=== üîπ TASK: {TASK} | STYLE: {STYLE} ===")
    print("Sending request to Ollama...")

    payload = {
        "model": MODEL,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        "temperature": 0.6,
        "top_p": 0.9,
        "max_tokens": 4096,
    }

    try:
        response = requests.post(URL, headers={"Content-Type": "application/json"}, json=payload, timeout=120)
        response.raise_for_status()
        data = response.json()

        # Handle OpenAI-compatible schema
        if "choices" in data and len(data["choices"]) > 0:
            text = data["choices"][0]["message"]["content"]
            print("\n=== RESPONSE ===")
            print(text.strip())
        else:
            print("Unexpected response format:\n", json.dumps(data, ensure_ascii=False, indent=2))

    except requests.RequestException as e:
        print("‚ùå Request failed:", e, file=sys.stderr)
        if e.response is not None:
            print("Response:", e.response.text, file=sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    call_ollama()